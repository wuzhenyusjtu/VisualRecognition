{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.0\n"
     ]
    }
   ],
   "source": [
    "# We are using OpenCV 3.1.0\n",
    "# To install OpenCV, run the following command in tensorflow virtual environment\n",
    "# $ conda install -c https://conda.binstar.org/menpo opencv3\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from random import randint\n",
    "# make sure we are using OpenCV version high than 3.0\n",
    "print cv2.__version__\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "X-Y Coordinate System on OpenCV\n",
    "x,y(Low)\n",
    "+ + + + + + x(high)\n",
    "+\n",
    "+\n",
    "+\n",
    "+\n",
    "+\n",
    "y(high)\n",
    "'''\n",
    "class Rectangle:\n",
    "    def __init__(self, x, y, w, h):\n",
    "        # x, y are the coordinates of the upper left point\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h\n",
    "    @staticmethod\n",
    "    # More detail, please refer to http://www.geeksforgeeks.org/find-two-rectangles-overlap/\n",
    "    # We are checking if two rectangles overlap or not\n",
    "    def check_2rects_overlap(rect1, rect2):\n",
    "        tl_x1, tl_y1 = rect1.x, rect1.y\n",
    "        br_x1, br_y1 = rect1.x + rect1.w, rect1.y + rect1.h\n",
    "        tl_x2, tl_y2 = rect2.x, rect2.y\n",
    "        br_x2, br_y2 = rect2.x + rect2.w, rect2.y + rect2.h\n",
    "        # If one rectangle is on the left side of the other\n",
    "        if tl_x1 > br_x2 or tl_x2 > br_x1:\n",
    "            return False\n",
    "        # If one rectangle in above other\n",
    "        if tl_y1 > br_y2 or tl_y2 > br_y1:\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ImageOperations:\n",
    "    @staticmethod\n",
    "    \n",
    "    def extract_objs_from_imgs_dir(src_imgs_dir, dst_objs_dir, scale_factor):\n",
    "        src_imgs_lst = []\n",
    "        '''\n",
    "        for img_name in os.listdir(imgs_dir):\n",
    "            if img_name.endswith(\".jpg\"):\n",
    "                images.append(img_name)\n",
    "        '''\n",
    "        import fnmatch\n",
    "        # Find out all the images in current directory by recursively visiting all the folders\n",
    "        for root, dirnames, filenames in os.walk(src_imgs_dir):\n",
    "            for filename in fnmatch.filter(filenames, '*.jpg'):\n",
    "                src_imgs_lst.append(os.path.join(root, filename))\n",
    "        # Extract objest out of the images and save them to the objs folder\n",
    "        for i in range(len(src_imgs_lst)):\n",
    "            ImageOperations.do_extraction_on_img(src_imgs_lst[i], os.path.join(objs_dir, str(i)+'.jpg'), scale_factor)\n",
    "\n",
    "    @staticmethod\n",
    "    # Extract object out of the image and save them to the destination\n",
    "    def do_extraction_on_img(img_name, obj_name, scale_factor):\n",
    "        img = cv2.imread(img_name)\n",
    "        # Convert image into grayscale\n",
    "        # Since the image has white background, it would be easier to extract the objects out in grayscale mode\n",
    "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # Do simple thresholding\n",
    "        # See example at http://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_thresholding/py_thresholding.html\n",
    "        ret, thresh = cv2.threshold(img_gray,250,255, cv2.THRESH_BINARY_INV)\n",
    "        # Find contours\n",
    "        _, contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        areas = [cv2.contourArea(c) for c in contours]\n",
    "        # The contour with largest area is the object of interest\n",
    "        max_index = np.argmax(areas)\n",
    "        cnt=contours[max_index]\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        # Use the following code to draw rectangle to validate our extraction is doing correctly\n",
    "        #cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        # Scale down the image by some factor\n",
    "        roi_resized = ImageOperations.resize_img(roi, scale_factor)\n",
    "        cv2.imwrite(obj_name, roi_resized)    \n",
    "    \n",
    "    @staticmethod\n",
    "    # resize the image by some factor\n",
    "    def resize_img(ori_img, scale_factor):\n",
    "        #new size (w,h)\n",
    "        newx,newy = ori_img.shape[1]/scale_factor, ori_img.shape[0]/scale_factor\n",
    "        new_img = cv2.resize(ori_img, (newx,newy))\n",
    "        return new_img\n",
    "    \n",
    "    @staticmethod\n",
    "    # blend the overlaying objects with the background\n",
    "    # refer to https://pythonprogramming.net/image-arithmetics-logic-python-opencv-tutorial/\n",
    "    def blend_overlays_with_bgd(overlay_lst, pos_lst, white_bgd, noisy_bgd):\n",
    "        for i in range(len(overlay_lst)):\n",
    "            overlay = overlay_lst[i]\n",
    "            (x,y,w,h) = pos_lst[i]\n",
    "            roi = white_bgd[y:y+h, x:x+w]\n",
    "            overlay2gray = cv2.cvtColor(overlay, cv2.COLOR_BGR2GRAY)\n",
    "            ret, mask = cv2.threshold(overlay2gray, 245, 255, cv2.THRESH_BINARY_INV)\n",
    "            mask_inv = cv2.bitwise_not(mask)\n",
    "\n",
    "            bgd_bg = cv2.bitwise_and(roi,roi,mask=mask_inv)\n",
    "            overlay_fg = cv2.bitwise_and(overlay,overlay,mask=mask)\n",
    "\n",
    "            dst = cv2.add(bgd_bg, overlay_fg)\n",
    "            white_bgd[y:y+h, x:x+w] = dst\n",
    "        return ImageOperations.seamless_clone_overlay_with_bgd(white_bgd, noisy_bgd)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    # See tutorial at http://www.learnopencv.com/seamless-cloning-using-opencv-python-cpp/\n",
    "    def seamless_clone_overlay_with_bgd(overlay, bgd):\n",
    "        mask = 255 * np.ones(overlay.shape, overlay.dtype)\n",
    "        width, height, _ = bgd.shape\n",
    "        center = (height/2, width/2)\n",
    "        mixed_clone = cv2.seamlessClone(overlay, bgd, mask, center, cv2.MIXED_CLONE)\n",
    "        return mixed_clone\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_objs_from_dir(objs_dir):\n",
    "    obj_names_lst = []\n",
    "    for img_name in os.listdir(objs_dir):\n",
    "        if img_name.endswith(\".jpg\"):\n",
    "                obj_names_lst.append(os.path.join(objs_dir, img_name))\n",
    "    print \"objects total:\\t\" + str(len(obj_names_lst))\n",
    "    return obj_names_lst\n",
    "\n",
    "\n",
    "    \n",
    "def create_composed_images_with_idl(noisy_bgd, idl_file_name, outputs_dir,\n",
    "                                        obj_names_lst, objs_total_in_img, \n",
    "                                        imgs_output_total, use_occlusion=False):\n",
    "    idl_file = open(idl_file_name, 'w')\n",
    "    bgd_w = noisy_bgd.shape[1]\n",
    "    bgd_h = noisy_bgd.shape[0]\n",
    "    white_bgd = np.full((bgd_h, bgd_w, 3), 255, np.uint8)\n",
    "    print noisy_bgd.shape\n",
    "    # It would be better if we create a noisy bgd with random noise\n",
    "    # In order to prevent our model to memorize the bgd\n",
    "    # It would be much easier for objects detection with bgd memorized\n",
    "    # noisy_bgd = np.random.randint(0, 255, (bgd_h, bgd_w, 3))\n",
    "    print noisy_bgd.shape\n",
    "    print noisy_bgd\n",
    "    for i in range(imgs_output_total):\n",
    "        white_bgd_copy = white_bgd.copy()\n",
    "        noisy_bgd_copy = noisy_bgd.copy()\n",
    "        mixed_filename = os.path.join(outputs_dir, 'output_'+str(i)+'mixed.jpg')\n",
    "        pos_lst = []\n",
    "        overlay_lst = []\n",
    "        rect_lst = []\n",
    "        line1 = []\n",
    "        line1.append('\"' + mixed_filename + '\": ')\n",
    "        one_decimal = \"{0:0.1f}\"\n",
    "        for j in range(objs_total_in_img):\n",
    "            obj_index = randint(0, len(obj_names_lst)-1)\n",
    "            obj = cv2.imread(obj_names_lst[obj_index])\n",
    "        \n",
    "            obj_w = obj.shape[1]\n",
    "            obj_h = obj.shape[0]\n",
    "        \n",
    "            obj_x = randint(0, bgd_w - obj_w - 1)        \n",
    "            obj_y = randint(0, bgd_h - obj_h - 1)\n",
    "\n",
    "            rect = Rectangle(obj_x, obj_y, obj_w, obj_h)\n",
    "            \n",
    "            rect_lst.append(rect)\n",
    "\n",
    "            overlay_lst.append(obj)\n",
    "            pos_lst.append((obj_x, obj_y, obj_w, obj_h))\n",
    "            #cv2.rectangle(bgd_copy,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        \n",
    "        if not use_occlusion:\n",
    "            ind2remove = []\n",
    "            for i in range(len(rect_lst)):\n",
    "                for j in range(i+1, len(rect_lst)):\n",
    "                    if Rectangle.check_2rects_overlap(rect_lst[i], rect_lst[j]):\n",
    "                        ind2remove.append(i)\n",
    "                    \n",
    "            pos_lst = [x for i,x in enumerate(pos_lst) if i not in ind2remove]\n",
    "            overlay_lst = [x for i,x in enumerate(overlay_lst) if i not in ind2remove]\n",
    "        \n",
    "        for (x,y,w,h) in pos_lst:\n",
    "            line1.append('(' + \n",
    "                one_decimal.format(x) + ', ' + \n",
    "                one_decimal.format(y) + ', ' + \n",
    "                one_decimal.format(x+w)  + ', ' + \n",
    "                one_decimal.format(y+h) + ')')\n",
    "            line1.append(',')\n",
    "        line1[-1] = ';' + \"\\n\"\n",
    "\n",
    "        composed_img = ImageOperations.blend_overlays_with_bgd(overlay_lst, pos_lst, white_bgd_copy, noisy_bgd_copy)\n",
    "\n",
    "        cv2.imwrite(mixed_filename, composed_img)\n",
    "\n",
    "        text_line1 = ''.join(line1)\n",
    "        idl_file.write(text_line1)\n",
    "    idl_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# You need to specify the image folder, objects folder and output folder name\n",
    "# You need to run the following process two times to get training data and testing data separately using different source of images data\n",
    "imgs_dir = '/home/zhenyu/Desktop/multiple_objects_recognition/prepare_data_set/imgs/imgs_test'\n",
    "objs_dir = '/home/zhenyu/Desktop/multiple_objects_recognition/prepare_data_set/objs/objs_test'\n",
    "outputs_dir = '/home/zhenyu/Desktop/multiple_objects_recognition/prepare_data_set/outputs_test'\n",
    "idl_file_name = 'test.idl'\n",
    "noisy_bgd_dir = '/home/zhenyu/Desktop/multiple_objects_recognition/prepare_data_set/noisy_bgd.jpg'\n",
    "noisy_bgd = cv2.imread(noisy_bgd_dir)\n",
    "noisy_bgd = cv2.resize(noisy_bgd, (640, 480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ImageOperations.extract_objs_from_imgs_dir(imgs_dir, objs_dir, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objects total:\t750\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "obj_names_lst = get_objs_from_dir(objs_dir)\n",
    "print len(obj_names_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 640, 3)\n",
      "(480, 640, 3)\n",
      "[[[118 130 142]\n",
      "  [116 128 140]\n",
      "  [116 128 140]\n",
      "  ..., \n",
      "  [126 137 145]\n",
      "  [126 137 145]\n",
      "  [125 136 144]]\n",
      "\n",
      " [[119 131 143]\n",
      "  [117 129 141]\n",
      "  [116 128 140]\n",
      "  ..., \n",
      "  [127 138 146]\n",
      "  [127 138 146]\n",
      "  [126 137 145]]\n",
      "\n",
      " [[119 131 143]\n",
      "  [117 129 141]\n",
      "  [117 129 141]\n",
      "  ..., \n",
      "  [129 140 148]\n",
      "  [129 140 148]\n",
      "  [128 139 147]]\n",
      "\n",
      " ..., \n",
      " [[ 73  95 137]\n",
      "  [ 72  94 135]\n",
      "  [ 78 100 141]\n",
      "  ..., \n",
      "  [ 88 133 184]\n",
      "  [ 88 133 184]\n",
      "  [ 95 142 193]]\n",
      "\n",
      " [[ 73  92 135]\n",
      "  [ 70  92 133]\n",
      "  [ 68  90 131]\n",
      "  ..., \n",
      "  [ 96 140 191]\n",
      "  [ 91 136 187]\n",
      "  [ 91 134 185]]\n",
      "\n",
      " [[ 74  92 135]\n",
      "  [ 75  97 138]\n",
      "  [ 72  94 135]\n",
      "  ..., \n",
      "  [ 97 137 189]\n",
      "  [ 93 135 187]\n",
      "  [ 95 138 189]]]\n"
     ]
    }
   ],
   "source": [
    "# You can change the parameter here to satisfy your own need\n",
    "# objs_total_in_img is the number of objects you want to have in one single image\n",
    "# imgs_output_total is the total output images for training or testing\n",
    "create_composed_images_with_idl(noisy_bgd, idl_file_name, outputs_dir, \n",
    "                                obj_names_lst, 10, 500, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
